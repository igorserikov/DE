{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received message: \u0000\u0000\u0000\u0000\u0003\u0006qwered \n",
      "Received message: \u0000\u0000\u0000\u0000\u0003\u0006qwered \n",
      "Received message: \u0000\u0000\u0000\u0000\u0003\u0006qwered \n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Читаем с автоматическим офсетом\n",
    "from confluent_kafka import Consumer, KafkaException\n",
    "# Конфигурация консюмера\n",
    "conf = {\n",
    "    'bootstrap.servers': 'localhost:9092',\n",
    "    'group.id': 'my-group11wfewf12',\n",
    "    'auto.offset.reset': 'earliest',  # Чтение с самого начала, если офсеты не найдены\n",
    "    'enable.auto.commit': True        # Включение автоматического коммита офсетов\n",
    "}\n",
    "# Создание консюмера\n",
    "consumer = Consumer(conf)\n",
    "# Подписка на топик\n",
    "consumer.subscribe(['my-avro-topic'])\n",
    "try:\n",
    "    for _ in range(5):\n",
    "        msg = consumer.poll(timeout=1.0)  # Ожидание новых сообщений  \n",
    "        if msg is None:\n",
    "            continue\n",
    "        if msg.error():\n",
    "            raise KafkaException(msg.error())\n",
    "        print(f'Received message: {msg.value().decode(\"utf-8\")}')\n",
    "        \n",
    "finally:\n",
    "    # Закрытие консюмера\n",
    "    consumer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Читаем с РУЧНЫМ офсетом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received message: \u0000\u0000\u0000\u0000\u0003\u0006qwered \n",
      "Received message: \u0000\u0000\u0000\u0000\u0003\u0006qwered \n",
      "Received message: \u0000\u0000\u0000\u0000\u0003\u0006qwered \n",
      "Received message: \u0000\u0000\u0000\u0000\u0003\u0006qwered \n",
      "Received message: \u0000\u0000\u0000\u0000\u0003\u0006qwered \n",
      "Received message: \u0000\u0000\u0000\u0000\u0003\u0006qwered \n",
      "Received message: \u0000\u0000\u0000\u0000\u0003\u0006qwered \n",
      "Received message: \u0000\u0000\u0000\u0000\u0003\u0006qwered \n"
     ]
    }
   ],
   "source": [
    "\n",
    "from confluent_kafka import Consumer, KafkaException\n",
    "# Конфигурация консюмера\n",
    "conf = {\n",
    "    'bootstrap.servers': 'localhost:9092',\n",
    "    'group.id': 'my-group-222222222', ## другая группа\n",
    "    'auto.offset.reset': 'earliest',  # Чтение с самого начала, если офсеты не найдены\n",
    "    'enable.auto.commit': False        # \n",
    "}\n",
    "# Создание консюмера\n",
    "consumer = Consumer(conf)\n",
    "# Подписка на топик\n",
    "consumer.subscribe(['my-avro-topic'])\n",
    "try:\n",
    "    for _ in range(15):\n",
    "        msg = consumer.poll(timeout=1.0)  # Ожидание новых сообщений  \n",
    "        if msg is None:\n",
    "            continue\n",
    "        if msg.error():\n",
    "            raise KafkaException(msg.error())\n",
    "        print(f'Received message: {msg.value().decode(\"utf-8\")}')\n",
    "        \n",
    "finally:\n",
    "    # Закрытие консюмера\n",
    "    consumer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтение офсетов для конкретной группы консумеров\n",
    "Для чтения текущих офсетов для группы консумеров можно использовать метод committed(partitions). Этот метод возвращает список офсетов для указанных разделов (partitions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition: 0, Offset: 9\n"
     ]
    }
   ],
   "source": [
    "from confluent_kafka import Consumer, TopicPartition\n",
    "\n",
    "# Конфигурация консюмера\n",
    "conf = {\n",
    "    'bootstrap.servers': 'localhost:9092',\n",
    "    'group.id': 'my-group11wfewf',\n",
    "    'auto.offset.reset': 'earliest',\n",
    "    'enable.auto.commit': False\n",
    "}\n",
    "\n",
    "consumer = Consumer(conf)\n",
    "consumer.subscribe(['my-topic'])\n",
    "\n",
    "# Получение текущих офсетов для группы консумеров по разделам топика\n",
    "partitions = [TopicPartition('my-topic', partition=0)]\n",
    "offsets = consumer.committed(partitions)\n",
    "\n",
    "for tp in offsets:\n",
    "    print(f'Partition: {tp.partition}, Offset: {tp.offset}')\n",
    "\n",
    "consumer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message delivered to my-topic [0] at offset 9\n",
      "Message delivered to my-topic [0] at offset 10\n",
      "Message delivered to my-topic [0] at offset 11\n",
      "Message delivered to my-topic [0] at offset 12\n",
      "finally\n"
     ]
    }
   ],
   "source": [
    "from confluent_kafka import Producer\n",
    "\n",
    "# Функция для обработки успешной доставки сообщений\n",
    "def delivery_report(err, msg):\n",
    "    if err is not None:\n",
    "        print(f'Message delivery failed: {err}')\n",
    "    else:\n",
    "        print(f'Message delivered to {msg.topic()} [{msg.partition()}] at offset {msg.offset()}')\n",
    "\n",
    "# Конфигурация продюсера\n",
    "conf = {\n",
    "    'bootstrap.servers': 'localhost:9092',  # Адрес Kafka брокера\n",
    "    'client.id': 'my-producer'                # Идентификатор клиента\n",
    "}\n",
    "\n",
    "# Создание экземпляра продюсера\n",
    "producer = Producer(conf)\n",
    "\n",
    "# Отправка сообщений\n",
    "try:\n",
    "    for i in range(4):\n",
    "        key = f'key-{i}'                # Ключ сообщения (опционально)\n",
    "        value = f'Hello Kafka {i}'      # Значение сообщения\n",
    "        producer.produce('my-topic', key=key, value=value, callback=delivery_report)\n",
    "\n",
    "        # Обработка асинхронных операций\n",
    "        producer.poll(0)  # Проверка на наличие ошибок и вызов обратных функций\n",
    "\n",
    "    # Ожидание отправки всех сообщений\n",
    "    producer.flush()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'Error while producing: {e}')\n",
    "\n",
    "finally:\n",
    "    # Закрытие продюсера\n",
    "    print('finally')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exactly-once semantics, EOS\n",
    "\n",
    " idempotent producer и настроек для транзакций\n",
    " Конфигурация продюсера:\n",
    "\n",
    "enable.idempotence: True: Включает идемпотентный режим для продюсера.\n",
    "transactional.id: Уникальный идентификатор для транзакций. Он должен быть уникальным для каждого продюсера в вашем приложении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%4|1729763253.160|GETPID|my-producer#producer-16| [thrd:main]: Failed to acquire transactional PID from broker TxnCoordinator/1: Broker: Not coordinator: retrying\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message delivered to my-topic [0] at offset 13\n",
      "Message delivered to my-topic [0] at offset 14\n",
      "Message delivered to my-topic [0] at offset 15\n",
      "Message delivered to my-topic [0] at offset 16\n"
     ]
    }
   ],
   "source": [
    "from confluent_kafka import Producer\n",
    "\n",
    "# Функция для обработки успешной доставки сообщений\n",
    "def delivery_report(err, msg):\n",
    "    if err is not None:\n",
    "        print(f'Message delivery failed: {err}')\n",
    "    else:\n",
    "        print(f'Message delivered to {msg.topic()} [{msg.partition()}] at offset {msg.offset()}')\n",
    "\n",
    "# Конфигурация продюсера\n",
    "conf = {\n",
    "    'bootstrap.servers': 'localhost:9092',  # Адрес Kafka брокера\n",
    "    'client.id': 'my-producer',              # Идентификатор клиента\n",
    "    'enable.idempotence': True,               # Включение идемпотентного режима\n",
    "    'acks': 'all',                            # Подтверждение от всех реплик\n",
    "    'retries': 5,                             # Количество попыток повторной отправки\n",
    "    'transactional.id': 'my-transactional-id'  # Идентификатор транзакции\n",
    "}\n",
    "\n",
    "# Создание экземпляра продюсера\n",
    "producer = Producer(conf)\n",
    "\n",
    "# Инициализация транзакции\n",
    "producer.init_transactions()\n",
    "\n",
    "try:\n",
    "    # Начало транзакции\n",
    "    producer.begin_transaction()\n",
    "\n",
    "    # Отправка сообщений\n",
    "    for i in range(4):\n",
    "        key = f'key-{i}'                # Ключ сообщения (опционально)\n",
    "        value = f'Hello Kafka {i}'      # Значение сообщения\n",
    "        producer.produce('my-topic', key=key, value=value, callback=delivery_report)\n",
    "\n",
    "        # Обработка асинхронных операций\n",
    "        producer.poll(0)  # Проверка на наличие ошибок и вызов обратных функций\n",
    "\n",
    "    # Завершение транзакции\n",
    "    producer.commit_transaction()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'Error while producing: {e}')\n",
    "    # Отмена транзакции в случае ошибки\n",
    "    producer.abort_transaction()\n",
    "\n",
    "finally:\n",
    "    # Ожидание отправки всех сообщений\n",
    "    producer.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AVRO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avro-файл — это бинарный файл, который используется для хранения данных, сериализованных в формате Avro. Он состоит из двух основных частей:\n",
    "\n",
    "Заголовок (Header): содержит метаданные и схему данных, которая описывает формат записей в файле.\n",
    "Тело (Data Blocks): содержит сами данные (записи), закодированные в соответствии с указанной схемой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Структура Avro-файла\n",
    "# 1. Заголовок (Header)\n",
    "# Каждый Avro-файл начинается с заголовка, который включает в себя:\n",
    "\n",
    "# Магическое число (magic): первые 4 байта файла — это последовательность байт\n",
    "#  0x4F 0x62 0x6A 0x01 (или строка \"Obj\\x01\"). Это используется для идентификации файла \n",
    "# как Avro-файл.\n",
    "#Метаданные (Metadata): хранит JSON-объект с информацией о схеме (например, \"avro.schema\") \n",
    "# и другую служебную информацию.\n",
    "#Синхронизационный маркер (Sync Marker): случайная последовательность из 16 байт, которая используется для синхронизации при чтении файла блоками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## работа с avro \n",
    "import fastavro\n",
    "\n",
    "# Определение схемы\n",
    "schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"User\",\n",
    "    \"fields\": [\n",
    "        {\"name\": \"name\", \"type\": \"string\"},\n",
    "        {\"name\": \"age\", \"type\": \"int\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Данные, которые будут сериализованы\n",
    "records = [\n",
    "    {\"name\": \"Alice\", \"age\": 25},\n",
    "    {\"name\": \"Bob\", \"age\": 30}\n",
    "]\n",
    "\n",
    "# Запись данных в Avro-файл\n",
    "with open('test.avro', 'wb') as out:\n",
    "    fastavro.writer(out, schema, records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Alice', 'age': 25}\n",
      "{'name': 'Bob', 'age': 30}\n"
     ]
    }
   ],
   "source": [
    "import fastavro\n",
    "\n",
    "# Чтение Avro-файла\n",
    "with open('test.avro', 'rb') as f:\n",
    "    reader = fastavro.reader(f)\n",
    "    for record in reader:\n",
    "        print(record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11d10a2c-1188-48bf-9540-0a866c711adb'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "str(uuid4())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
