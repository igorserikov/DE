{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Список \n",
    "response = requests.get(\"http://localhost:8081/subjects\")\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при удалении схемы: 404\n",
      "{\"error_code\":40401,\"message\":\"Subject 'my-avro-topic-value' not found. io.confluent.rest.exceptions.RestNotFoundException: Subject 'my-avro-topic-value' not found.\\nio.confluent.rest.exceptions.RestNotFoundException: Subject 'my-avro-topic-value' not found.\\n\\tat io.confluent.kafka.schemaregistry.rest.exceptions.Errors.subjectNotFoundException(Errors.java:78)\\n\\tat io.confluent.kafka.schemaregistry.rest.resources.SubjectsResource.deleteSubject(SubjectsResource.java:278)\\n\\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\n\\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\\n\\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n\\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\\n\\tat org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)\\n\\tat org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:134)\\n\\tat org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:177)\\n\\tat org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$VoidOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:159)\\n\\tat org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:81)\\n\\tat org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)\\n\\tat org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)\\n\\tat org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)\\n\\tat org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)\\n\\tat org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)\\n\\tat org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)\\n\\tat org.glassfish.jersey.internal.Errors.process(Errors.java:292)\\n\\tat org.glassfish.jersey.internal.Errors.process(Errors.java:274)\\n\\tat org.glassfish.jersey.internal.Errors.process(Errors.java:244)\\n\\tat org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)\\n\\tat org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)\\n\\tat org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)\\n\\tat org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)\\n\\tat org.glassfish.jersey.servlet.ServletContainer.serviceImpl(ServletContainer.java:378)\\n\\tat org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:553)\\n\\tat org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:494)\\n\\tat org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:431)\\n\\tat org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)\\n\\tat org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:54)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\\n\\tat io.confluent.kafka.schemaregistry.rest.RequestIdHandler.handle(RequestIdHandler.java:51)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\\n\\tat org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)\\n\\tat org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)\\n\\tat org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)\\n\\tat org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)\\n\\tat org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:722)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\\n\\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\\n\\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\\n\\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\\n\\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\\n\\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\\n\\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\\n\\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\\n\\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n\"}\n"
     ]
    }
   ],
   "source": [
    "### УДАЛЕНИЕ\n",
    "import requests\n",
    "\n",
    "# URL для удаления схемы\n",
    "url = 'http://localhost:8081/subjects/my-avro-topic-value'\n",
    "\n",
    "# Отправляем DELETE-запрос\n",
    "response = requests.delete(url)\n",
    "\n",
    "# Проверяем результат\n",
    "if response.status_code == 200:\n",
    "    print(f\"Схема для 'my-topic4-value' успешно удалена.\")\n",
    "else:\n",
    "    print(f\"Ошибка при удалении схемы: {response.status_code}\\n{response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error_code': 40401,\n",
       " 'message': \"Subject 'my-avro-topic-value' not found. io.confluent.rest.exceptions.RestNotFoundException: Subject 'my-avro-topic-value' not found.\\nio.confluent.rest.exceptions.RestNotFoundException: Subject 'my-avro-topic-value' not found.\\n\\tat io.confluent.kafka.schemaregistry.rest.exceptions.Errors.subjectNotFoundException(Errors.java:78)\\n\\tat io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource.getSchemaByVersion(SubjectVersionsResource.java:152)\\n\\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\n\\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\\n\\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n\\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\\n\\tat org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)\\n\\tat org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:134)\\n\\tat org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:177)\\n\\tat org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$TypeOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:219)\\n\\tat org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:81)\\n\\tat org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)\\n\\tat org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)\\n\\tat org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)\\n\\tat org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)\\n\\tat org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)\\n\\tat org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)\\n\\tat org.glassfish.jersey.internal.Errors.process(Errors.java:292)\\n\\tat org.glassfish.jersey.internal.Errors.process(Errors.java:274)\\n\\tat org.glassfish.jersey.internal.Errors.process(Errors.java:244)\\n\\tat org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)\\n\\tat org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)\\n\\tat org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)\\n\\tat org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)\\n\\tat org.glassfish.jersey.servlet.ServletContainer.serviceImpl(ServletContainer.java:378)\\n\\tat org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:553)\\n\\tat org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:494)\\n\\tat org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:431)\\n\\tat org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)\\n\\tat org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:54)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\\n\\tat io.confluent.kafka.schemaregistry.rest.RequestIdHandler.handle(RequestIdHandler.java:51)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\\n\\tat org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)\\n\\tat org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)\\n\\tat org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)\\n\\tat org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)\\n\\tat org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:772)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\\n\\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\\n\\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\\n\\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\\n\\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\\n\\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\\n\\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\\n\\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\\n\\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\\n\\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n\"}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(\"http://localhost:8081/subjects/my-avro-topic-value/versions/latest\")\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Полученная схема: {\"title\":\"UserList\",\"type\":\"array\",\"items\":{\"type\":\"object\",\"properties\":{\"name\":{\"type\":\"string\"},\"age\":{\"type\":\"integer\"},\"email\":{\"type\":\"string\"}},\"required\":[\"name\",\"age\"]}}\n"
     ]
    }
   ],
   "source": [
    "schema_id = 1  # Замените на нужный ID\n",
    "url = f'http://localhost:8081/schemas/ids/{schema_id}'\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    schema = response.json().get('schema')\n",
    "    print('Полученная схема:', schema)\n",
    "else:\n",
    "    print('Ошибка при получении схемы:', response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AVRO-схема"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#пробуем зарегистрировать несколько разновидностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Схема зарегистрирована с ID: 2\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "import requests\n",
    "import json\n",
    "\n",
    "url = 'http://localhost:8081/subjects/my-topic-value/versions'\n",
    "schema = {\n",
    "    \"schema\": json.dumps({\n",
    "        \"type\": \"record\",\n",
    "        \"name\": \"User\",\n",
    "        \"fields\": [\n",
    "            {\"name\": \"name\", \"type\": \"string\"},\n",
    "            {\"name\": \"age\", \"type\": \"int\"}\n",
    "            ,\n",
    "            {\"name\": \"email\", \"type\": \"int\"}#, \"default\": \"\"}\n",
    "        ]\n",
    "    })\n",
    "}\n",
    "## POST-запрос!!!\n",
    "response = requests.post(url, json=schema)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    schema_id = response.json().get('id')\n",
    "    print('Схема зарегистрирована с ID:', schema_id)\n",
    "else:\n",
    "    print('Ошибка при регистрации схемы:', response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(\"http://localhost:8081/subjects/my-avro-topic-value/versions\")\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subject': 'my-avro-topic-value',\n",
       " 'version': 1,\n",
       " 'id': 3,\n",
       " 'schema': '{\"type\":\"record\",\"name\":\"User\",\"fields\":[{\"name\":\"name\",\"type\":\"string\"},{\"name\":\"favorite_number\",\"type\":\"long\"},{\"name\":\"favorite_color\",\"type\":\"string\"}]}'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(\"http://localhost:8081/subjects/my-avro-topic-value/versions/latest\")\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для AVRO - Консюмер определит версию схемы по магическим байтикам.\n",
    "\n",
    "Для JSON надо делать ручками, например - писать версию в само соообщение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AVRO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avro-файл — это бинарный файл, который используется для хранения данных, сериализованных в формате Avro. Он состоит из двух основных частей:\n",
    "\n",
    "Заголовок (Header): содержит метаданные и схему данных, которая описывает формат записей в файле.\n",
    "Тело (Data Blocks): содержит сами данные (записи), закодированные в соответствии с указанной схемой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"df\":1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Структура Avro-файла\n",
    "# 1. Заголовок (Header)\n",
    "# Каждый Avro-файл начинается с заголовка, который включает в себя:\n",
    "\n",
    "# Магическое число (magic): первые 4 байта файла — это последовательность байт\n",
    "#  0x4F 0x62 0x6A 0x01 (или строка \"Obj\\x01\"). Это используется для идентификации файла \n",
    "# как Avro-файл.\n",
    "#Метаданные (Metadata): хранит JSON-объект с информацией о схеме (например, \"avro.schema\") \n",
    "# и другую служебную информацию.\n",
    "#Синхронизационный маркер (Sync Marker): случайная последовательность из 16 байт, которая используется для синхронизации при чтении файла блоками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## работа с avro \n",
    "import fastavro\n",
    "\n",
    "# Определение схемы\n",
    "schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"User\",\n",
    "    \"fields\": [\n",
    "        {\"name\": \"name\", \"type\": \"string\"},\n",
    "        {\"name\": \"age\", \"type\": \"int\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Данные, которые будут сериализованы\n",
    "records = [\n",
    "    {\"name\": \"Alice\", \"age\": 25},\n",
    "    {\"name\": \"Bob\", \"age\": 30}\n",
    "]\n",
    "\n",
    "# Запись данных в Avro-файл\n",
    "with open('test.avro', 'wb') as out:\n",
    "    fastavro.writer(out, schema, records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Alice', 'age': 25}\n",
      "{'name': 'Bob', 'age': 30}\n"
     ]
    }
   ],
   "source": [
    "import fastavro\n",
    "\n",
    "# Чтение Avro-файла\n",
    "with open('test.avro', 'rb') as f:\n",
    "    reader = fastavro.reader(f)\n",
    "    for record in reader:\n",
    "        print(record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11d10a2c-1188-48bf-9540-0a866c711adb'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "str(uuid4())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пример в kafka_avro_producer.py \n",
    "======================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening to topic 'my-avro-topic'...\n",
      "Raw key (bytes): b'c3806228-478c-4f49-af3a-a68cd9b90a55'\n",
      "Raw value (bytes): b'\\x00\\x00\\x00\\x00\\x03\\x06qwe\\x02\\x08red '\n",
      "Key (decoded): c3806228-478c-4f49-af3a-a68cd9b90a55\n",
      "Value (decoded): \u0000\u0000\u0000\u0000\u0003\u0006qwered \n",
      "Raw key (bytes): b'd1a94380-1134-4700-9287-c955fce110e3'\n",
      "Raw value (bytes): b'\\x00\\x00\\x00\\x00\\x03\\x06qwe\\x02\\x08red '\n",
      "Key (decoded): d1a94380-1134-4700-9287-c955fce110e3\n",
      "Value (decoded): \u0000\u0000\u0000\u0000\u0003\u0006qwered \n",
      "Raw key (bytes): b'7b1ff7f8-1897-4c80-b32a-b13c561a6026'\n",
      "Raw value (bytes): b'\\x00\\x00\\x00\\x00\\x03\\x06qwe\\x02\\x08red '\n",
      "Key (decoded): 7b1ff7f8-1897-4c80-b32a-b13c561a6026\n",
      "Value (decoded): \u0000\u0000\u0000\u0000\u0003\u0006qwered \n",
      "Raw key (bytes): b'af0f93e1-d8ac-4920-a34f-d9f7c3f6c970'\n",
      "Raw value (bytes): b'\\x00\\x00\\x00\\x00\\x03\\x06qwe\\x02\\x08red '\n",
      "Key (decoded): af0f93e1-d8ac-4920-a34f-d9f7c3f6c970\n",
      "Value (decoded): \u0000\u0000\u0000\u0000\u0003\u0006qwered \n"
     ]
    }
   ],
   "source": [
    "### Читаем сырые байтики\n",
    "from confluent_kafka import Consumer\n",
    "\n",
    "# Конфигурация консьюмера\n",
    "conf = {\n",
    "    'bootstrap.servers': 'localhost:9092',\n",
    "    'group.id': 'my_group111',\n",
    "    'auto.offset.reset': 'earliest'  # Чтение сообщений с начала, если нет сохранённых оффсетов\n",
    "}\n",
    "\n",
    "# Создаем консьюмера\n",
    "consumer = Consumer(conf)\n",
    "\n",
    "# Подписка на топик\n",
    "topic = \"my-avro-topic\"\n",
    "consumer.subscribe([topic])\n",
    "\n",
    "print(f\"Listening to topic '{topic}'...\")\n",
    "\n",
    "# Чтение сообщений\n",
    "try:\n",
    "    for x in range(10):\n",
    "        msg = consumer.poll(1.0)  # Ожидание сообщений\n",
    "\n",
    "        if msg is None:\n",
    "            continue\n",
    "\n",
    "        if msg.error():\n",
    "            print(f\"Consumer error: {msg.error()}\")\n",
    "            continue\n",
    "\n",
    "        # Получение \"сырых\" данных сообщения\n",
    "        raw_key = msg.key()  # Байты ключа\n",
    "        raw_value = msg.value()  # Байты значения\n",
    "\n",
    "        # Вывод байтов сообщения\n",
    "        print(f\"Raw key (bytes): {raw_key}\")\n",
    "        print(f\"Raw value (bytes): {raw_value}\")\n",
    "\n",
    "        # Если хотите вывести их в текстовом виде (для строк):\n",
    "        print(f\"Key (decoded): {raw_key.decode('utf-8') if raw_key else None}\")\n",
    "        print(f\"Value (decoded): {raw_value.decode('utf-8') if raw_value else None}\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Consumer interrupted.\")\n",
    "finally:\n",
    "    consumer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пытаемся читать обычным консюмером AVRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144386/1827773791.py:13: DeprecationWarning: AvroConsumer has been deprecated. Use AvroDeserializer instead.\n",
      "  consumer = AvroConsumer(conf)\n"
     ]
    },
    {
     "ename": "SerializerError",
     "evalue": "Message deserialization failed for message at my-avro-topic [0] offset 0: message does not start with magic byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSerializerError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/myenv/lib/python3.12/site-packages/confluent_kafka/avro/__init__.py:184\u001b[0m, in \u001b[0;36mAvroConsumer.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message\u001b[38;5;241m.\u001b[39mkey() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 184\u001b[0m     decoded_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_serializer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m     message\u001b[38;5;241m.\u001b[39mset_key(decoded_key)\n",
      "File \u001b[0;32m~/myenv/lib/python3.12/site-packages/confluent_kafka/avro/serializer/message_serializer.py:234\u001b[0m, in \u001b[0;36mMessageSerializer.decode_message\u001b[0;34m(self, message, is_key)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic \u001b[38;5;241m!=\u001b[39m MAGIC_BYTE:\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SerializerError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage does not start with magic byte\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    235\u001b[0m decoder_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_decoder_func(schema_id, payload, is_key)\n",
      "\u001b[0;31mSerializerError\u001b[0m: message does not start with magic byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSerializerError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m---> 21\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[43mconsumer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m msg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/myenv/lib/python3.12/site-packages/confluent_kafka/avro/__init__.py:187\u001b[0m, in \u001b[0;36mAvroConsumer.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    185\u001b[0m             message\u001b[38;5;241m.\u001b[39mset_key(decoded_key)\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m SerializerError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 187\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SerializerError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage deserialization failed for message at \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m [\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m] offset \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    188\u001b[0m             message\u001b[38;5;241m.\u001b[39mtopic(),\n\u001b[1;32m    189\u001b[0m             message\u001b[38;5;241m.\u001b[39mpartition(),\n\u001b[1;32m    190\u001b[0m             message\u001b[38;5;241m.\u001b[39moffset(),\n\u001b[1;32m    191\u001b[0m             e))\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m message\n",
      "\u001b[0;31mSerializerError\u001b[0m: Message deserialization failed for message at my-avro-topic [0] offset 0: message does not start with magic byte"
     ]
    }
   ],
   "source": [
    "from confluent_kafka import Consumer\n",
    "from confluent_kafka.avro import AvroConsumer\n",
    "\n",
    "# Конфигурация консьюмера\n",
    "conf = {\n",
    "    'bootstrap.servers': 'localhost:9092',\n",
    "    'group.id': 'my_group11',\n",
    "    'auto.offset.reset': 'earliest',  # Начинать чтение с самого начала, если нет смещений\n",
    "    'schema.registry.url': 'http://localhost:8081',  # Schema Registry URL\n",
    "}\n",
    "\n",
    "# Создаем Avro-консьюмера\n",
    "consumer = AvroConsumer(conf)\n",
    "\n",
    "# Подписываемся на топик\n",
    "consumer.subscribe(['my-avro-topic'])\n",
    "\n",
    "# Чтение сообщений\n",
    "try:\n",
    "    for x in range(10):\n",
    "        msg = consumer.poll(1.0)\n",
    "\n",
    "        if msg is None:\n",
    "            continue\n",
    "\n",
    "        # Выводим полученное сообщение\n",
    "        print(f\"Получено сообщение: {msg.value()}\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    consumer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subject': 'my-avro-topic-value',\n",
       " 'version': 1,\n",
       " 'id': 3,\n",
       " 'schema': '{\"type\":\"record\",\"name\":\"User\",\"fields\":[{\"name\":\"name\",\"type\":\"string\"},{\"name\":\"favorite_number\",\"type\":\"long\"},{\"name\":\"favorite_color\",\"type\":\"string\"}]}'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(\"http://localhost:8081/subjects/my-avro-topic-value/versions/latest\")\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ДОПОЛНИТЕЛЬНЫЕ МАТЕРИАЛЫ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Конфигурация Schema Registry\n",
    "schema_registry_url = 'http://localhost:8081'\n",
    "subject = 'my-json-topic-value'  # Название subject для вашей схемы\n",
    "\n",
    "# JSON-схема с массивом пользователей\n",
    "json_schema = {\n",
    "    \"title\": \"UserList\",\n",
    "    \"type\": \"array\",\n",
    "    \"items\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"name\": {\"type\": \"string\"},\n",
    "            \"age\": {\"type\": \"integer\"},\n",
    "            \"email\": {\"type\": \"string\"}\n",
    "        },\n",
    "        \"required\": [\"name\", \"age\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Подготовка данных для регистрации схемы\n",
    "data = {\n",
    "    \"schema\": json.dumps(json_schema),\n",
    "    \"schemaType\": \"JSON\"  # Указываем тип схемы\n",
    "}\n",
    "\n",
    "# Запрос на регистрацию схемы\n",
    "response = requests.post(\n",
    "    f'{schema_registry_url}/subjects/{subject}/versions',\n",
    "    headers={'Content-Type': 'application/json'},\n",
    "    data=json.dumps(data)\n",
    ")\n",
    "\n",
    "# Проверка ответа\n",
    "if response.status_code == 200:\n",
    "    print(f\"Схема успешно зарегистрирована: {response.json()}\")\n",
    "else:\n",
    "    print(f\"Ошибка регистрации схемы: {response.status_code} {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer\n",
    "from confluent_kafka.schema_registry import SchemaRegistryClient\n",
    "from confluent_kafka.schema_registry.json_schema import JSONSerializer\n",
    "from confluent_kafka.serialization import SerializationContext, MessageField\n",
    "import json\n",
    "import uuid\n",
    "\n",
    "# Конфигурация Schema Registry\n",
    "schema_registry_conf = {'url': \"http://localhost:8081\"}\n",
    "schema_registry_client = SchemaRegistryClient(schema_registry_conf)\n",
    "\n",
    "# Получаем последнюю версию схемы из Schema Registry\n",
    "subject = 'my-json-topic-value'  # Субъект (subject), под которым схема зарегистрирована\n",
    "schema_response = schema_registry_client.get_latest_version(subject)\n",
    "schema_id = schema_response.schema_id\n",
    "json_schema_str = schema_response.schema.schema_str\n",
    "print(json_schema_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем JSONSerializer с использованием загруженной схемы\n",
    "json_serializer = JSONSerializer(json_schema_str, schema_registry_client)\n",
    "\n",
    "# Конфигурация продюсера Kafka\n",
    "producer_conf = {\n",
    "    'bootstrap.servers': 'localhost:9092'\n",
    "}\n",
    "producer = Producer(producer_conf)\n",
    "\n",
    "# Топик Kafka\n",
    "topic = 'my-json-topic'\n",
    "\n",
    "# Пример JSON-сообщения, которое соответствует схеме\n",
    "data = [\n",
    "    {\"name\": \"Alice\", \"age\": 30, \"email\": \"alice@example.com\"},\n",
    "    {\"name\": \"Bob\", \"age\": 25, \"email\": \"bob@example.com\"}\n",
    "]\n",
    "\n",
    "# Функция для обратного вызова при доставке сообщения\n",
    "def delivery_report(err, msg):\n",
    "    if err is not None:\n",
    "        print(f\"Delivery failed for record {msg.key()}: {err}\")\n",
    "    else:\n",
    "        print(f\"Record {msg.key()} successfully produced to {msg.topic()} [{msg.partition()}] at offset {msg.offset()}\")\n",
    "\n",
    "# Производство сообщений в топик Kafka\n",
    "try:\n",
    "    key = str(uuid.uuid4())  # Генерация уникального ключа для каждого сообщения\n",
    "    serialized_value = json_serializer(data, SerializationContext(topic, MessageField.VALUE))\n",
    "    \n",
    "    producer.produce(\n",
    "        topic=topic,\n",
    "        key=key,\n",
    "        value=serialized_value,\n",
    "        on_delivery=delivery_report\n",
    "    )\n",
    "    producer.flush()  # Дождаться отправки всех сообщений\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "print(\"Message sent successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## пишем другую схему\n",
    "# Создаем JSONSerializer с использованием загруженной схемы\n",
    "json_serializer = JSONSerializer(json_schema_str, schema_registry_client)\n",
    "\n",
    "# Конфигурация продюсера Kafka\n",
    "producer_conf = {\n",
    "    'bootstrap.servers': 'localhost:9092'\n",
    "}\n",
    "producer = Producer(producer_conf)\n",
    "\n",
    "# Топик Kafka\n",
    "topic = 'my-json-topic'\n",
    "\n",
    "# Пример JSON-сообщения, которое соответствует схеме\n",
    "data = [\n",
    "    {\"name1\": \"Alice\", \"age\": 30, \"email\": \"alice@example.com\"},\n",
    "    {\"name2\": \"Bob\", \"age\": 25, \"email\": \"bob@example.com\"}\n",
    "]\n",
    "\n",
    "# Функция для обратного вызова при доставке сообщения\n",
    "def delivery_report(err, msg):\n",
    "    if err is not None:\n",
    "        print(f\"Delivery failed for record {msg.key()}: {err}\")\n",
    "    else:\n",
    "        print(f\"Record {msg.key()} successfully produced to {msg.topic()} [{msg.partition()}] at offset {msg.offset()}\")\n",
    "\n",
    "# Производство сообщений в топик Kafka\n",
    "try:\n",
    "    key = str(uuid.uuid4())  # Генерация уникального ключа для каждого сообщения\n",
    "    serialized_value = json_serializer(data, SerializationContext(topic, MessageField.VALUE))\n",
    "    \n",
    "    producer.produce(\n",
    "        topic=topic,\n",
    "        key=key,\n",
    "        value=serialized_value,\n",
    "        on_delivery=delivery_report\n",
    "    )\n",
    "    producer.flush()  # Дождаться отправки всех сообщений\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "print(\"Message sent successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
