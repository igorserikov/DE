{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my-avro-topic-value']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Список \n",
    "response = requests.get(\"http://localhost:8081/subjects\")\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Схема для 'my-topic4-value' успешно удалена.\n"
     ]
    }
   ],
   "source": [
    "### УДАЛЕНИЕ\n",
    "import requests\n",
    "\n",
    "# URL для удаления схемы\n",
    "url = 'http://localhost:8081/subjects/my-avro-topic-value'\n",
    "\n",
    "# Отправляем DELETE-запрос\n",
    "response = requests.delete(url)\n",
    "\n",
    "# Проверяем результат\n",
    "if response.status_code == 200:\n",
    "    print(f\"Схема для 'my-topic4-value' успешно удалена.\")\n",
    "else:\n",
    "    print(f\"Ошибка при удалении схемы: {response.status_code[:10]}\\n{response.text[:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\'subject\\': \\'my-avro-topic-value\\', \\'version\\': 1, \\'id\\': 1, \\'schema\\': \\'{\"type\":\"record\",\"name\":\"User\",'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(\"http://localhost:8081/subjects/my-avro-topic-value/versions/latest\")\n",
    "str(response.json())[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Полученная схема: {\"title\":\"UserList\",\"type\":\"array\",\"items\":{\"type\":\"object\",\"properties\":{\"name\":{\"type\":\"string\"},\"age\":{\"type\":\"integer\"},\"email\":{\"type\":\"string\"}},\"required\":[\"name\",\"age\"]}}\n"
     ]
    }
   ],
   "source": [
    "schema_id = 1  # Замените на нужный ID\n",
    "url = f'http://localhost:8081/schemas/ids/{schema_id}'\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    schema = response.json().get('schema')\n",
    "    print('Полученная схема:', schema)\n",
    "else:\n",
    "    print('Ошибка при получении схемы:', response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AVRO-схема"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#пробуем зарегистрировать несколько разновидностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Схема зарегистрирована с ID: 4\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "import requests\n",
    "import json\n",
    "\n",
    "url = 'http://localhost:8081/subjects/my-topic-value/versions'\n",
    "schema = {\n",
    "    \"schema\": json.dumps({\n",
    "        \"type\": \"record\",\n",
    "        \"name\": \"User\",\n",
    "        \"fields\": [\n",
    "            {\"name\": \"name\", \"type\": \"string\"},\n",
    "            {\"name\": \"age\", \"type\": \"int\"}\n",
    "            ,\n",
    "            {\"name\": \"email\", \"type\": \"int\", \"default\": \"\"}\n",
    "        ]\n",
    "    })\n",
    "}\n",
    "## POST-запрос!!!\n",
    "response = requests.post(url, json=schema)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    schema_id = response.json().get('id')\n",
    "    print('Схема зарегистрирована с ID:', schema_id)\n",
    "else:\n",
    "    print('Ошибка при регистрации схемы:', response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(\"http://localhost:8081/subjects/my-avro-topic-value/versions\")\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subject': 'my-avro-topic-value',\n",
       " 'version': 1,\n",
       " 'id': 1,\n",
       " 'schema': '{\"type\":\"record\",\"name\":\"User\",\"fields\":[{\"name\":\"name\",\"type\":\"string\"},{\"name\":\"favorite_number\",\"type\":\"long\"},{\"name\":\"favorite_color\",\"type\":\"string\"}]}'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(\"http://localhost:8081/subjects/my-avro-topic-value/versions/latest\")\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для AVRO - Консюмер определит версию схемы по магическим байтикам.\n",
    "\n",
    "Для JSON надо делать ручками, например - писать версию в само соообщение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AVRO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avro-файл — это бинарный файл, который используется для хранения данных, сериализованных в формате Avro. Он состоит из двух основных частей:\n",
    "\n",
    "Заголовок (Header): содержит метаданные и схему данных, которая описывает формат записей в файле.\n",
    "Тело (Data Blocks): содержит сами данные (записи), закодированные в соответствии с указанной схемой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Структура Avro-файла\n",
    "# 1. Заголовок (Header)\n",
    "# Каждый Avro-файл начинается с заголовка, который включает в себя:\n",
    "\n",
    "# Магическое число (magic): первые 4 байта файла — это последовательность байт\n",
    "#  0x4F 0x62 0x6A 0x01 (или строка \"Obj\\x01\"). Это используется для идентификации файла \n",
    "# как Avro-файл.\n",
    "#Метаданные (Metadata): хранит JSON-объект с информацией о схеме (например, \"avro.schema\") \n",
    "# и другую служебную информацию.\n",
    "#Синхронизационный маркер (Sync Marker): случайная последовательность из 16 байт, которая используется для синхронизации при чтении файла блоками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## работа с avro \n",
    "import fastavro\n",
    "\n",
    "# Определение схемы\n",
    "schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"User\",\n",
    "    \"fields\": [\n",
    "        {\"name\": \"name\", \"type\": \"string\"},\n",
    "        {\"name\": \"age\", \"type\": \"int\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Данные, которые будут сериализованы\n",
    "records = [\n",
    "    {\"name\": \"Alice\", \"age\": 25},\n",
    "    {\"name\": \"Bob\", \"age\": 30}\n",
    "]\n",
    "\n",
    "# Запись данных в Avro-файл\n",
    "with open('test.avro', 'wb') as out:\n",
    "    fastavro.writer(out, schema, records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Alice', 'age': 25}\n",
      "{'name': 'Bob', 'age': 30}\n"
     ]
    }
   ],
   "source": [
    "import fastavro\n",
    "\n",
    "# Чтение Avro-файла\n",
    "with open('test.avro', 'rb') as f:\n",
    "    reader = fastavro.reader(f)\n",
    "    for record in reader:\n",
    "        print(record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11d10a2c-1188-48bf-9540-0a866c711adb'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "str(uuid4())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пример в kafka_avro_producer.py \n",
    "======================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening to topic 'my-avro-topic'...\n",
      "Raw key (bytes): b'7105d34f-40e7-4588-8e74-d70c8f2989e0'\n",
      "Raw value (bytes): b'\\x00\\x00\\x00\\x00\\x01\\x06qwe\\x02\\x08red '\n",
      "Key (decoded): 7105d34f-40e7-4588-8e74-d70c8f2989e0\n",
      "Value (decoded): \u0000\u0000\u0000\u0000\u0001\u0006qwered \n",
      "Raw key (bytes): b'4c5d96d9-3046-47f4-b5d9-a145733e553d'\n",
      "Raw value (bytes): b'\\x00\\x00\\x00\\x00\\x01\\x06qwe\\x02\\x08red '\n",
      "Key (decoded): 4c5d96d9-3046-47f4-b5d9-a145733e553d\n",
      "Value (decoded): \u0000\u0000\u0000\u0000\u0001\u0006qwered \n",
      "Raw key (bytes): b'9a764074-df69-45ee-b833-540168d61e8d'\n",
      "Raw value (bytes): b'\\x00\\x00\\x00\\x00\\x01\\x06qwe\\x02\\x08red '\n",
      "Key (decoded): 9a764074-df69-45ee-b833-540168d61e8d\n",
      "Value (decoded): \u0000\u0000\u0000\u0000\u0001\u0006qwered \n",
      "Raw key (bytes): b'75593f37-3e89-4e1d-a00f-e2efbc986dac'\n",
      "Raw value (bytes): b'\\x00\\x00\\x00\\x00\\x01\\x06qwe\\x02\\x08red '\n",
      "Key (decoded): 75593f37-3e89-4e1d-a00f-e2efbc986dac\n",
      "Value (decoded): \u0000\u0000\u0000\u0000\u0001\u0006qwered \n",
      "Raw key (bytes): b'ede0bc9e-1067-48c7-b93b-16568092615a'\n",
      "Raw value (bytes): b'\\x00\\x00\\x00\\x00\\x01\\x06qwe\\x02\\x08red '\n",
      "Key (decoded): ede0bc9e-1067-48c7-b93b-16568092615a\n",
      "Value (decoded): \u0000\u0000\u0000\u0000\u0001\u0006qwered \n",
      "Raw key (bytes): b'3782b89a-4606-4898-9a68-88218e769cda'\n",
      "Raw value (bytes): b'\\x00\\x00\\x00\\x00\\x01\\x06qwe\\x02\\x08red '\n",
      "Key (decoded): 3782b89a-4606-4898-9a68-88218e769cda\n",
      "Value (decoded): \u0000\u0000\u0000\u0000\u0001\u0006qwered \n",
      "Raw key (bytes): b'3d8343d6-53a4-416e-ba27-76617beff070'\n",
      "Raw value (bytes): b'\\x00\\x00\\x00\\x00\\x01\\x06qwe\\x02\\x08red '\n",
      "Key (decoded): 3d8343d6-53a4-416e-ba27-76617beff070\n",
      "Value (decoded): \u0000\u0000\u0000\u0000\u0001\u0006qwered \n",
      "Raw key (bytes): b'fcd2a016-bc97-4688-9f4d-3908e065b679'\n",
      "Raw value (bytes): b'\\x00\\x00\\x00\\x00\\x01\\x06qwe\\x02\\x08red '\n",
      "Key (decoded): fcd2a016-bc97-4688-9f4d-3908e065b679\n",
      "Value (decoded): \u0000\u0000\u0000\u0000\u0001\u0006qwered \n",
      "Raw key (bytes): b'1f0c0eb5-44f6-4eda-8a09-27da7ce8a088'\n",
      "Raw value (bytes): b'\\x00\\x00\\x00\\x00\\x01\\x06qwe\\x02\\x08red '\n",
      "Key (decoded): 1f0c0eb5-44f6-4eda-8a09-27da7ce8a088\n",
      "Value (decoded): \u0000\u0000\u0000\u0000\u0001\u0006qwered \n",
      "Raw key (bytes): b'ea9251cb-cdaf-4676-95ef-fb79cd8964de'\n",
      "Raw value (bytes): b'\\x00\\x00\\x00\\x00\\x01\\x06qwe\\x02\\x08red '\n",
      "Key (decoded): ea9251cb-cdaf-4676-95ef-fb79cd8964de\n",
      "Value (decoded): \u0000\u0000\u0000\u0000\u0001\u0006qwered \n"
     ]
    }
   ],
   "source": [
    "### Читаем сырые байтики\n",
    "from confluent_kafka import Consumer\n",
    "\n",
    "# Конфигурация консьюмера\n",
    "conf = {\n",
    "    'bootstrap.servers': 'localhost:9092',\n",
    "    'group.id': 'my_group111111',\n",
    "    'auto.offset.reset': 'earliest'  # Чтение сообщений с начала, если нет сохранённых оффсетов\n",
    "}\n",
    "\n",
    "# Создаем консьюмера\n",
    "consumer = Consumer(conf)\n",
    "\n",
    "# Подписка на топик\n",
    "topic = \"my-avro-topic\"\n",
    "consumer.subscribe([topic])\n",
    "\n",
    "print(f\"Listening to topic '{topic}'...\")\n",
    "\n",
    "# Чтение сообщений\n",
    "try:\n",
    "    for x in range(10):\n",
    "        msg = consumer.poll(1.0)  # Ожидание сообщений\n",
    "\n",
    "        if msg is None:\n",
    "            continue\n",
    "\n",
    "        if msg.error():\n",
    "            print(f\"Consumer error: {msg.error()}\")\n",
    "            continue\n",
    "\n",
    "        # Получение \"сырых\" данных сообщения\n",
    "        raw_key = msg.key()  # Байты ключа\n",
    "        raw_value = msg.value()  # Байты значения\n",
    "\n",
    "        # Вывод байтов сообщения\n",
    "        print(f\"Raw key (bytes): {raw_key}\")\n",
    "        print(f\"Raw value (bytes): {raw_value}\")\n",
    "\n",
    "        # Если хотите вывести их в текстовом виде (для строк):\n",
    "        print(f\"Key (decoded): {raw_key.decode('utf-8') if raw_key else None}\")\n",
    "        print(f\"Value (decoded): {raw_value.decode('utf-8') if raw_value else None}\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Consumer interrupted.\")\n",
    "finally:\n",
    "    consumer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пытаемся читать обычным консюмером AVRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_199284/195624817.py:13: DeprecationWarning: AvroConsumer has been deprecated. Use AvroDeserializer instead.\n",
      "  consumer = AvroConsumer(conf)\n"
     ]
    },
    {
     "ename": "SerializerError",
     "evalue": "Message deserialization failed for message at my-avro-topic [0] offset 0: message does not start with magic byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSerializerError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/myenv/lib/python3.12/site-packages/confluent_kafka/avro/__init__.py:184\u001b[0m, in \u001b[0;36mAvroConsumer.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message\u001b[38;5;241m.\u001b[39mkey() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 184\u001b[0m     decoded_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_serializer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m     message\u001b[38;5;241m.\u001b[39mset_key(decoded_key)\n",
      "File \u001b[0;32m~/myenv/lib/python3.12/site-packages/confluent_kafka/avro/serializer/message_serializer.py:234\u001b[0m, in \u001b[0;36mMessageSerializer.decode_message\u001b[0;34m(self, message, is_key)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic \u001b[38;5;241m!=\u001b[39m MAGIC_BYTE:\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SerializerError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage does not start with magic byte\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    235\u001b[0m decoder_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_decoder_func(schema_id, payload, is_key)\n",
      "\u001b[0;31mSerializerError\u001b[0m: message does not start with magic byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSerializerError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m---> 21\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[43mconsumer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m msg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/myenv/lib/python3.12/site-packages/confluent_kafka/avro/__init__.py:187\u001b[0m, in \u001b[0;36mAvroConsumer.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    185\u001b[0m             message\u001b[38;5;241m.\u001b[39mset_key(decoded_key)\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m SerializerError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 187\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SerializerError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage deserialization failed for message at \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m [\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m] offset \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    188\u001b[0m             message\u001b[38;5;241m.\u001b[39mtopic(),\n\u001b[1;32m    189\u001b[0m             message\u001b[38;5;241m.\u001b[39mpartition(),\n\u001b[1;32m    190\u001b[0m             message\u001b[38;5;241m.\u001b[39moffset(),\n\u001b[1;32m    191\u001b[0m             e))\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m message\n",
      "\u001b[0;31mSerializerError\u001b[0m: Message deserialization failed for message at my-avro-topic [0] offset 0: message does not start with magic byte"
     ]
    }
   ],
   "source": [
    "from confluent_kafka import Consumer\n",
    "from confluent_kafka.avro import AvroConsumer\n",
    "\n",
    "# Конфигурация консьюмера\n",
    "conf = {\n",
    "    'bootstrap.servers': 'localhost:9092',\n",
    "    'group.id': 'my_group1111',\n",
    "    'auto.offset.reset': 'earliest',  # Начинать чтение с самого начала, если нет смещений\n",
    "    'schema.registry.url': 'http://localhost:8081',  # Schema Registry URL\n",
    "}\n",
    "\n",
    "# Создаем Avro-консьюмера\n",
    "consumer = AvroConsumer(conf)\n",
    "\n",
    "# Подписываемся на топик\n",
    "consumer.subscribe(['my-avro-topic'])\n",
    "\n",
    "# Чтение сообщений\n",
    "try:\n",
    "    for x in range(10):\n",
    "        msg = consumer.poll(1.0)\n",
    "\n",
    "        if msg is None:\n",
    "            continue\n",
    "\n",
    "        # Выводим полученное сообщение\n",
    "        print(f\"Получено сообщение: {msg.value()}\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    consumer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subject': 'my-avro-topic-value',\n",
       " 'version': 2,\n",
       " 'id': 3,\n",
       " 'schema': '{\"type\":\"record\",\"name\":\"User\",\"fields\":[{\"name\":\"name\",\"type\":\"string\"},{\"name\":\"favorite_number\",\"type\":\"long\"},{\"name\":\"favorite_color\",\"type\":\"string\"}]}'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(\"http://localhost:8081/subjects/my-avro-topic-value/versions/latest\")\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ДОПОЛНИТЕЛЬНЫЕ МАТЕРИАЛЫ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Конфигурация Schema Registry\n",
    "schema_registry_url = 'http://localhost:8081'\n",
    "subject = 'my-json-topic-value'  # Название subject для вашей схемы\n",
    "\n",
    "# JSON-схема с массивом пользователей\n",
    "json_schema = {\n",
    "    \"title\": \"UserList\",\n",
    "    \"type\": \"array\",\n",
    "    \"items\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"name\": {\"type\": \"string\"},\n",
    "            \"age\": {\"type\": \"integer\"},\n",
    "            \"email\": {\"type\": \"string\"}\n",
    "        },\n",
    "        \"required\": [\"name\", \"age\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Подготовка данных для регистрации схемы\n",
    "data = {\n",
    "    \"schema\": json.dumps(json_schema),\n",
    "    \"schemaType\": \"JSON\"  # Указываем тип схемы\n",
    "}\n",
    "\n",
    "# Запрос на регистрацию схемы\n",
    "response = requests.post(\n",
    "    f'{schema_registry_url}/subjects/{subject}/versions',\n",
    "    headers={'Content-Type': 'application/json'},\n",
    "    data=json.dumps(data)\n",
    ")\n",
    "\n",
    "# Проверка ответа\n",
    "if response.status_code == 200:\n",
    "    print(f\"Схема успешно зарегистрирована: {response.json()}\")\n",
    "else:\n",
    "    print(f\"Ошибка регистрации схемы: {response.status_code} {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer\n",
    "from confluent_kafka.schema_registry import SchemaRegistryClient\n",
    "from confluent_kafka.schema_registry.json_schema import JSONSerializer\n",
    "from confluent_kafka.serialization import SerializationContext, MessageField\n",
    "import json\n",
    "import uuid\n",
    "\n",
    "# Конфигурация Schema Registry\n",
    "schema_registry_conf = {'url': \"http://localhost:8081\"}\n",
    "schema_registry_client = SchemaRegistryClient(schema_registry_conf)\n",
    "\n",
    "# Получаем последнюю версию схемы из Schema Registry\n",
    "subject = 'my-json-topic-value'  # Субъект (subject), под которым схема зарегистрирована\n",
    "schema_response = schema_registry_client.get_latest_version(subject)\n",
    "schema_id = schema_response.schema_id\n",
    "json_schema_str = schema_response.schema.schema_str\n",
    "print(json_schema_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем JSONSerializer с использованием загруженной схемы\n",
    "json_serializer = JSONSerializer(json_schema_str, schema_registry_client)\n",
    "\n",
    "# Конфигурация продюсера Kafka\n",
    "producer_conf = {\n",
    "    'bootstrap.servers': 'localhost:9092'\n",
    "}\n",
    "producer = Producer(producer_conf)\n",
    "\n",
    "# Топик Kafka\n",
    "topic = 'my-json-topic'\n",
    "\n",
    "# Пример JSON-сообщения, которое соответствует схеме\n",
    "data = [\n",
    "    {\"name\": \"Alice\", \"age\": 30, \"email\": \"alice@example.com\"},\n",
    "    {\"name\": \"Bob\", \"age\": 25, \"email\": \"bob@example.com\"}\n",
    "]\n",
    "\n",
    "# Функция для обратного вызова при доставке сообщения\n",
    "def delivery_report(err, msg):\n",
    "    if err is not None:\n",
    "        print(f\"Delivery failed for record {msg.key()}: {err}\")\n",
    "    else:\n",
    "        print(f\"Record {msg.key()} successfully produced to {msg.topic()} [{msg.partition()}] at offset {msg.offset()}\")\n",
    "\n",
    "# Производство сообщений в топик Kafka\n",
    "try:\n",
    "    key = str(uuid.uuid4())  # Генерация уникального ключа для каждого сообщения\n",
    "    serialized_value = json_serializer(data, SerializationContext(topic, MessageField.VALUE))\n",
    "    \n",
    "    producer.produce(\n",
    "        topic=topic,\n",
    "        key=key,\n",
    "        value=serialized_value,\n",
    "        on_delivery=delivery_report\n",
    "    )\n",
    "    producer.flush()  # Дождаться отправки всех сообщений\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "print(\"Message sent successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## пишем другую схему\n",
    "# Создаем JSONSerializer с использованием загруженной схемы\n",
    "json_serializer = JSONSerializer(json_schema_str, schema_registry_client)\n",
    "\n",
    "# Конфигурация продюсера Kafka\n",
    "producer_conf = {\n",
    "    'bootstrap.servers': 'localhost:9092'\n",
    "}\n",
    "producer = Producer(producer_conf)\n",
    "\n",
    "# Топик Kafka\n",
    "topic = 'my-json-topic'\n",
    "\n",
    "# Пример JSON-сообщения, которое соответствует схеме\n",
    "data = [\n",
    "    {\"name1\": \"Alice\", \"age\": 30, \"email\": \"alice@example.com\"},\n",
    "    {\"name2\": \"Bob\", \"age\": 25, \"email\": \"bob@example.com\"}\n",
    "]\n",
    "\n",
    "# Функция для обратного вызова при доставке сообщения\n",
    "def delivery_report(err, msg):\n",
    "    if err is not None:\n",
    "        print(f\"Delivery failed for record {msg.key()}: {err}\")\n",
    "    else:\n",
    "        print(f\"Record {msg.key()} successfully produced to {msg.topic()} [{msg.partition()}] at offset {msg.offset()}\")\n",
    "\n",
    "# Производство сообщений в топик Kafka\n",
    "try:\n",
    "    key = str(uuid.uuid4())  # Генерация уникального ключа для каждого сообщения\n",
    "    serialized_value = json_serializer(data, SerializationContext(topic, MessageField.VALUE))\n",
    "    \n",
    "    producer.produce(\n",
    "        topic=topic,\n",
    "        key=key,\n",
    "        value=serialized_value,\n",
    "        on_delivery=delivery_report\n",
    "    )\n",
    "    producer.flush()  # Дождаться отправки всех сообщений\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "print(\"Message sent successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
